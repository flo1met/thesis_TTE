---
title: "Process example"
format: html
---

# import true PE
```{r}
true_pe <- read.csv("../out/True Values/TRUE_PE.csv")
```


# import R
```{r}
files_R <- list.files("../out/R", full.names = TRUE)
files_1000_R <- files_R[grepl("R_MRD_data_1000_\\d+\\.arrow$", files_R)]
```

```{r}
true_pe <- read.csv("../out/True Values/TRUE_PE.csv")
names(true_pe) <- c("X", "followup_time", "True_MRD")
```


```{r}
R_out_1000 <- files_1000_R %>%
  map(~ read_feather(.x) %>% mutate(nsim = sub(".*_(\\d+)\\.arrow$", "\\1", basename(.x)))) %>%
  bind_rows()


R_out_combined_1000 <- R_out_1000 %>%
  group_by(followup_time) %>%
  summarize(MRD = mean(survival_diff),
            CIlow = mean(`2.5%`),
            CIhigh = mean(`97.5%`))

CI_1000 <- R_out_1000 %>%
  group_by(followup_time) %>%
  mutate(SD = sd(survival_diff),
         CIlow = mean(survival_diff) - 1.96*SD,
         CIhigh = mean(survival_diff) + 1.96*SD) %>%
  summarise(CIlow = mean(CIlow),
            CIhigh = mean(CIhigh))

R_out_1000 <- R_out_1000 %>%
  left_join(CI_1000, by = "followup_time")
```

coverage
(include the error corrected one?)
```{r}
R_out_1000 <- R_out_1000 %>%
  left_join(true_pe, by = "followup_time")

(coverage_R_full <- R_out_1000 %>%
  group_by(followup_time) %>%
  summarise(coverage = mean(True_MRD > `2.5%` & True_MRD < `97.5%`, na.rm = TRUE)))

(coverage_R <- mean(R_out_1000$True_MRD > R_out_1000$`2.5%` & R_out_1000$True_MRD < R_out_1000$`97.5%`))

```

```{r}
library(ggplot2)



ggplot(R_out_1000, aes(y = nsim)) +
  geom_segment(aes(x = `2.5%`, xend = `97.5%`, yend = nsim), color = "blue") +
  #geom_vline(xintercept = True_MRD, color = "red", linetype = "dashed") +
  facet_wrap(~ followup_time, scales = "free_y") +
  labs(title = paste("Bootstrap Confidence Intervals (Coverage:", round(coverage_R * 100, 2), "%)"),
       x = "Parameter Estimate", 
       y = "Simulation Index") +
  theme_minimal()


```



```{r}
(MCSE <- sqrt((coverage_R * (1-coverage_R))/nrow(R_out_1000)))
```



bias
```{r}
mean(R_out_1000$`2.5%` - R_out_1000$CIlow)
mean(R_out_1000$`97.5%` - R_out_1000$CIhigh)
```


var
```{r}
(var_low_R <- var(R_out_1000$`2.5%`))
(var_high_R <- var(R_out_1000$`97.5%`))
```


# import Julia
```{r}
files_Julia <- list.files("../out/Julia", full.names = TRUE)
files_1000_Julia <- files_Julia[grepl("Julia_MRD_data_1000_\\d+\\.arrow$", files_Julia)]
```

```{r}
true_pe <- read.csv("../out/True Values/TRUE_PE.csv")
```


```{r}
Julia_out_1000 <- files_1000_Julia %>%
  map(~ read_feather(.x) %>% mutate(nsim = sub(".*_(\\d+)\\.arrow$", "\\1", basename(.x)))) %>%
  bind_rows()


Julia_out_combined_1000 <- Julia_out_1000 %>%
  group_by(fup) %>%
  summarize(MRD = mean(MRD_hat),
            CIlow = mean(CIlow_emp),
            CIhigh = mean(CIhigh_emp))

CI_1000 <- Julia_out_1000 %>%
  group_by(fup) %>%
  mutate(SD = sd(MRD_hat),
         CIlow = mean(MRD_hat) - 1.96*SD,
         CIhigh = mean(MRD_hat) + 1.96*SD) %>%
  summarise(CIlow = mean(CIlow),
            CIhigh = mean(CIhigh))

Julia_out_1000 <- Julia_out_1000 %>%
  left_join(CI_1000, by = "fup")
```

coverage
```{r}
Julia_out_1000 <- Julia_out_1000 %>%
  left_join(true_pe, by = "fup")

(coverage <- Julia_out_1000 %>%
  group_by(fup) %>%
  summarise(coverage = mean(True_MRD > CIlow_emp & True_MRD < CIhigh_emp, na.rm = TRUE)))
(coverage_Julia <- mean(Julia_out_1000$True_MRD > Julia_out_1000$CIlow_emp & Julia_out_1000$True_MRD < Julia_out_1000$CIhigh_emp))


(coverage_pct <- Julia_out_1000 %>%
  group_by(fup) %>%
  summarise(coverage = mean(True_MRD > CIlow_pct & True_MRD < CIhigh_pct, na.rm = TRUE)))
(coverage_Julia_pct <- mean(Julia_out_1000$True_MRD > Julia_out_1000$CIlow_pct & Julia_out_1000$True_MRD < Julia_out_1000$CIhigh_pct))
```

bias
```{r}
(bias_low_Julia <- mean(Julia_out_1000$CIlow_emp - Julia_out_1000$CIlow))
(bias_high_Julia <- mean(Julia_out_1000$CIhigh_emp - Julia_out_1000$CIhigh))
```


variance
```{r}
(var_low_Julia <- var(Julia_out_1000$CIlow_emp))
(var_high_Julia <- var(Julia_out_1000$CIhigh_emp))
```








```{r}
coverage
coverage_R_full
coverage_pct
```










Tempirical coverage probability measures the proportion of simulated datasets where the true parameter value lies within the confidence interval, assessing the accuracy of the interval estimation. The Type-I error rate indicates the frequency of incorrectly rejecting a true null hypothesis, while power reflects the probability of correctly rejecting a false null hypothesis. \\
The width of the confidence interval provides insight into the precision of the estimator, with narrower intervals typically preferred. Standard error quantifies the estimate's variability, and Monte Carlo standard error estimates the uncertainty introduced by the simulation process. 


